{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3e6dec9",
   "metadata": {},
   "source": [
    "# CORAL Loss Experiments: Walkability Score Prediction\n",
    "\n",
    "This notebook runs systematic experiments comparing different **image backbones**, **tabular encoders**, and **fusion mechanisms** using CORAL ordinal regression loss for predicting walkability scores (1-5) from street-view images and user demographics.\n",
    "\n",
    "**Data**: ~24K training / ~6K test samples with:\n",
    "- **Image**: Street-view photographs (`image_path`)\n",
    "- **Tabular**: age, gender, childhood_country, childhood_area, disability, walking_frequency, residence_type\n",
    "- **Label**: `rating` (ordinal 1-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc74c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_NamespacePath(['/Users/ahmademami/Library/CloudStorage/OneDrive-UNSW/TERM 1/Github/aglone/autogluon/autogluon', 'autogluon', '__editable__.autogluon-1.4.1b20260213.finder.__path_hook__', 'autogluon', '__editable__.autogluon_common-1.4.1b20260213.finder.__path_hook__', 'autogluon', '__editable__.autogluon_core-1.4.1b20260213.finder.__path_hook__', 'autogluon', '__editable__.autogluon_eda-1.4.1b20260213.finder.__path_hook__', 'autogluon', '__editable__.autogluon_features-1.4.1b20260213.finder.__path_hook__', 'autogluon', '__editable__.autogluon_multimodal-1.4.1b20260213.finder.__path_hook__', 'autogluon', '__editable__.autogluon_tabular-1.4.1b20260213.finder.__path_hook__', 'autogluon', '__editable__.autogluon_timeseries-1.4.1b20260213.finder.__path_hook__'])\n",
      "/Users/ahmademami/Library/CloudStorage/OneDrive-UNSW/TERM 1/Github/aglone/autogluon/multimodal/src/autogluon/multimodal/__init__.py\n",
      "/Users/ahmademami/Library/CloudStorage/OneDrive-UNSW/TERM 1/Github/aglone/autogluon/tabular/src/autogluon/tabular/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import autogluon\n",
    "import autogluon.multimodal\n",
    "import autogluon.tabular\n",
    "\n",
    "print(autogluon.__path__)                   # namespace search paths\n",
    "print(autogluon.multimodal.__file__)        # actual file path\n",
    "print(autogluon.tabular.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d90153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20260213_055335\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.1b20260213\n",
      "Python Version:     3.10.19\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 25.2.0: Tue Nov 18 21:08:48 PST 2025; root:xnu-12377.61.12~1/RELEASE_ARM64_T8132\n",
      "CPU Count:          10\n",
      "Pytorch Version:    2.7.1\n",
      "CUDA Version:       CUDA is not available\n",
      "GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)\n",
      "Memory Avail:       4.14 GB / 16.00 GB (25.9%)\n",
      "Disk Space Avail:   314.12 GB / 460.43 GB (68.2%)\n",
      "===================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Using 50 training samples for quick CPU test\n",
      "Missing files - Train: 0, Test: 0\n",
      "\n",
      "Label distribution in training data:\n",
      "rating\n",
      "1     4\n",
      "2     5\n",
      "3    16\n",
      "4    17\n",
      "5     8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique classes: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]\n",
      "\n",
      "============================================================\n",
      "TESTING CORAL LOSS ON CPU\n",
      "============================================================\n",
      "Loss function: coral\n",
      "Epochs: 3\n",
      "Batch size: 4\n",
      "Training samples: 50\n",
      "Test samples: 20\n",
      "============================================================\n",
      "\n",
      "Starting training with CORAL loss...\n",
      "‚ö†Ô∏è LOOK FOR DEBUG MESSAGES ABOUT LOSS FUNCTION SELECTION ‚ö†Ô∏è\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "AutoMM starts to create your model. ‚ú®‚ú®‚ú®\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir /Users/ahmademami/Library/CloudStorage/OneDrive-UNSW/TERM 1/Github/aglone/autogluon/AutogluonModels/ag-20260213_055335\n",
      "    ```\n",
      "\n",
      "Seed set to 0\n",
      "The hyperparameter name optim.learning_rate is depreciated. We recommend using the new name optim.lr instead.The deprecated hyperparameter will raise an exception starting in AutoGluon 1.4.0\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 0\n",
      "\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "üí° Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "\n",
      "  | Name              | Type                | Params | Mode  | FLOPs\n",
      "--------------------------------------------------------------------------\n",
      "0 | model             | MultimodalFusionMLP | 12.5 M | train | 0    \n",
      "1 | validation_metric | MulticlassAccuracy  | 0      | train | 0    \n",
      "2 | loss_func         | CoralLoss           | 0      | train | 0    \n",
      "--------------------------------------------------------------------------\n",
      "12.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.5 M    Total params\n",
      "49.972    Total estimated model params size (MB)\n",
      "178       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3816883e595c4aba9efd360fdfb8dd5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "get_loss_func_per_run called in base.py:\n",
      "  config.optim.loss_func: coral\n",
      "  problem_type: multiclass\n",
      "  mixup_active: False\n",
      "  model type: <class 'autogluon.multimodal.models.fusion.fusion_mlp.MultimodalFusionMLP'>\n",
      "  model has num_classes? True\n",
      "  model.num_classes: 4\n",
      "======================================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "get_loss_func called:\n",
      "  problem_type: multiclass\n",
      "  loss_func_name: coral\n",
      "  mixup_active: False\n",
      "  kwargs: {'num_classes': 5}\n",
      "============================================================\n",
      "\n",
      "DEBUG: Initializing CoralLoss with kwargs keys: ['num_classes']\n",
      "\n",
      "======================================================================\n",
      "üî• CORAL LOSS ACTIVATED!\n",
      "   num_classes: 5\n",
      "   output_dim: 4 (cumulative ordinal regression)\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 1: 'val_accuracy' reached 0.30000 (best 0.30000), saving model to '/Users/ahmademami/Library/CloudStorage/OneDrive-UNSW/TERM 1/Github/aglone/autogluon/AutogluonModels/ag-20260213_055335/epoch=0-step=1.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 2: 'val_accuracy' reached 0.30000 (best 0.30000), saving model to '/Users/ahmademami/Library/CloudStorage/OneDrive-UNSW/TERM 1/Github/aglone/autogluon/AutogluonModels/ag-20260213_055335/epoch=1-step=2.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 3: 'val_accuracy' reached 0.20000 (best 0.30000), saving model to '/Users/ahmademami/Library/CloudStorage/OneDrive-UNSW/TERM 1/Github/aglone/autogluon/AutogluonModels/ag-20260213_055335/epoch=2-step=3.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start to fuse 3 checkpoints via the greedy soup algorithm.\n",
      "üí° Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5bbd071371d4fa4999de622dd4076ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1316d1767724cb7929a02a0f65a1da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b685eac864f54c478e11ab7e5028aa49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoMM has created your model. üéâüéâüéâ\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"/Users/ahmademami/Library/CloudStorage/OneDrive-UNSW/TERM 1/Github/aglone/autogluon/AutogluonModels/ag-20260213_055335\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training completed!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Load and Prepare Data\n",
    "# ---------------------------\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Loading data...\")\n",
    "train_df = pd.read_csv(TRAIN_CSV, index_col=0)\n",
    "test_df  = pd.read_csv(TEST_CSV,  index_col=0)\n",
    "\n",
    "# Drop non-feature columns\n",
    "train_df = train_df.drop(columns=[c for c in DROP_COLS if c in train_df.columns])\n",
    "test_df  = test_df.drop(columns=[c for c in DROP_COLS if c in test_df.columns])\n",
    "\n",
    "# Use a subset for quick CPU experiments (increase for GPU)\n",
    "TRAIN_SAMPLE = 200    # ‚Üê Increase to len(train_df) for full training\n",
    "TEST_SAMPLE  = 100    # ‚Üê Increase to len(test_df) for full evaluation\n",
    "\n",
    "train_df = train_df.sample(n=min(TRAIN_SAMPLE, len(train_df)), random_state=42).reset_index(drop=True)\n",
    "test_df  = test_df.sample(n=min(TEST_SAMPLE, len(test_df)), random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Absolute image paths\n",
    "train_df = add_abs_image_paths(train_df, IMAGE_COL, IMG_DIR)\n",
    "test_df  = add_abs_image_paths(test_df,  IMAGE_COL, IMG_DIR)\n",
    "\n",
    "# Verify files exist\n",
    "missing = (~train_df[IMAGE_COL].map(os.path.exists)).sum()\n",
    "print(f\"Missing image files: {missing}/{len(train_df)}\")\n",
    "\n",
    "# Data summary\n",
    "print(f\"\\nTrain: {len(train_df)} samples, Test: {len(test_df)} samples\")\n",
    "print(f\"Columns: {list(train_df.columns)}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(train_df[LABEL_COL].value_counts().sort_index())\n",
    "print(f\"\\nSample row:\\n{train_df.iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33f3d9e",
   "metadata": {},
   "source": [
    "## Available Models in AutoGluon Multimodal\n",
    "\n",
    "### Image Backbones (`model.timm_image.checkpoint_name`)\n",
    "Any model from the [timm library](https://github.com/huggingface/pytorch-image-models) (1000+ models). Key options:\n",
    "\n",
    "| Model | Size | Notes |\n",
    "|---|---|---|\n",
    "| `resnet18` | 11M | Fast baseline |\n",
    "| `resnet50` | 25M | Standard CNN |\n",
    "| `mobilenetv3_large_100` | 5M | Mobile-efficient (medium_quality preset) |\n",
    "| `efficientnet_b0` | 5M | Efficient scaling |\n",
    "| `efficientnet_b3` | 12M | Better accuracy |\n",
    "| `convnext_tiny` | 28M | Modern ConvNet |\n",
    "| `convnext_base_in22ft1k` | 89M | Strong ConvNet |\n",
    "| `swin_base_patch4_window7_224` | 88M | Vision Transformer |\n",
    "| `swin_large_patch4_window7_224` | 197M | Large ViT (best_quality preset) |\n",
    "| `vit_base_patch16_clip_224.laion2b_ft_in12k_in1k` | 87M | CLIP-pretrained ViT |\n",
    "| `caformer_b36.sail_in22k_ft_in1k` | 99M | MetaFormer (high_quality preset) |\n",
    "\n",
    "### Text/Tabular Encoders (`model.hf_text.checkpoint_name`)\n",
    "Any model from [HuggingFace](https://huggingface.co/models). Key options:\n",
    "\n",
    "| Model | Size | Notes |\n",
    "|---|---|---|\n",
    "| `prajjwal1/bert-tiny` | 4M | Ultra-fast testing |\n",
    "| `google/electra-small-discriminator` | 14M | Medium preset |\n",
    "| `google/electra-base-discriminator` | 110M | High_quality preset |\n",
    "| `microsoft/deberta-v3-small` | 44M | Strong text encoder |\n",
    "| `microsoft/deberta-v3-base` | 86M | Best_quality preset |\n",
    "| `distilroberta-base` | 82M | Fast & accurate |\n",
    "\n",
    "### Tabular-Specific Models\n",
    "| Model | Config Key | Notes |\n",
    "|---|---|---|\n",
    "| Numerical MLP | `model.numerical_mlp.*` | MLP for numerical features |\n",
    "| Categorical MLP | `model.categorical_mlp.*` | Embedding + MLP for categories |\n",
    "| FT-Transformer | `model.ft_transformer.*` | Transformer for tabular data |\n",
    "\n",
    "### Fusion Mechanisms\n",
    "| Fusion | Config Key | Notes |\n",
    "|---|---|---|\n",
    "| **MLP Fusion** | `model.fusion_mlp.*` | Concatenate + MLP (default, fast) |\n",
    "| **Transformer Fusion** | `model.fusion_transformer.*` | Cross-attention between modalities |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231eca7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing predictions on test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7dcac3944844b794ea0a1023b1801e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71f518ac28b4645b87550b8173e8205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions shape: (20,)\n",
      "Predictions:\n",
      "0    2\n",
      "1    3\n",
      "2    3\n",
      "3    1\n",
      "4    3\n",
      "5    3\n",
      "6    3\n",
      "7    3\n",
      "8    5\n",
      "9    3\n",
      "Name: rating, dtype: int64\n",
      "\n",
      "Unique predicted values: [np.int64(1), np.int64(2), np.int64(3), np.int64(5)]\n",
      "\n",
      "============================================================\n",
      "Testing predict_proba (probability outputs)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities shape: (20, 5)\n",
      "\n",
      "First 5 probability distributions:\n",
      "          1         2         3         4         5\n",
      "0  0.193754  0.223485  0.190285  0.209797  0.182679\n",
      "1  0.183307  0.176777  0.254238  0.209016  0.176661\n",
      "2  0.198294  0.166579  0.229737  0.211078  0.194311\n",
      "3  0.228144  0.162556  0.203276  0.219948  0.186076\n",
      "4  0.235119  0.161531  0.239180  0.166392  0.197777\n",
      "\n",
      "Probabilities sum to 1? True\n",
      "\n",
      "============================================================\n",
      "Comparing predictions with ground truth...\n",
      "   True  Predicted\n",
      "0     4          2\n",
      "1     4          3\n",
      "2     3          3\n",
      "3     1          1\n",
      "4     5          3\n",
      "5     3          3\n",
      "6     1          3\n",
      "7     4          3\n",
      "8     4          5\n",
      "9     4          3\n",
      "\n",
      "Test Accuracy: 25.00%\n",
      "Mean Absolute Error: 1.300\n",
      "\n",
      "============================================================\n",
      "CORAL LOSS TEST COMPLETED SUCCESSFULLY!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# EXPERIMENT CONFIGURATIONS\n",
    "# ============================================================\n",
    "# Each experiment tests a different combination of:\n",
    "#   - Loss function (CORAL vs CrossEntropy)\n",
    "#   - Image backbone\n",
    "#   - Tabular processing (text encoder converts tabular to text,\n",
    "#     or use dedicated numerical_mlp + categorical_mlp)\n",
    "#   - Fusion mechanism (MLP vs Transformer)\n",
    "#\n",
    "# To run on GPU: set \"env.num_gpus\": 1 and increase batch size\n",
    "# To use full data: increase TRAIN_SAMPLE / TEST_SAMPLE above\n",
    "# ============================================================\n",
    "\n",
    "MAX_EPOCHS = 5          # ‚Üê Increase for real experiments (10-20)\n",
    "TIME_LIMIT = 600        # seconds per experiment\n",
    "NUM_GPUS   = 0          # ‚Üê Set to 1 for GPU training\n",
    "BATCH_SIZE = 4 if NUM_GPUS == 0 else 32\n",
    "\n",
    "# Base config shared across experiments\n",
    "base_config = {\n",
    "    \"optim.max_epochs\": MAX_EPOCHS,\n",
    "    \"optim.learning_rate\": 1e-4,\n",
    "    \"env.num_gpus\": NUM_GPUS,\n",
    "    \"env.per_gpu_batch_size\": BATCH_SIZE,\n",
    "    \"env.num_workers\": 0 if NUM_GPUS == 0 else 4,\n",
    "    \"env.num_workers_inference\": 0 if NUM_GPUS == 0 else 4,\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# Define experiments\n",
    "# ============================================================\n",
    "experiments = {}\n",
    "\n",
    "# --- 1. CORAL + ResNet18 (small baseline) ---\n",
    "experiments[\"coral_resnet18\"] = {\n",
    "    **base_config,\n",
    "    \"optim.loss_func\": \"coral\",\n",
    "    \"model.timm_image.checkpoint_name\": \"resnet18\",\n",
    "    \"model.hf_text.checkpoint_name\": \"prajjwal1/bert-tiny\",\n",
    "}\n",
    "\n",
    "# --- 2. CrossEntropy + ResNet18 (baseline comparison) ---\n",
    "experiments[\"ce_resnet18\"] = {\n",
    "    **base_config,\n",
    "    # no loss_func ‚Üí defaults to CrossEntropyLoss\n",
    "    \"model.timm_image.checkpoint_name\": \"resnet18\",\n",
    "    \"model.hf_text.checkpoint_name\": \"prajjwal1/bert-tiny\",\n",
    "}\n",
    "\n",
    "# --- 3. CORAL + ResNet50 (stronger CNN) ---\n",
    "experiments[\"coral_resnet50\"] = {\n",
    "    **base_config,\n",
    "    \"optim.loss_func\": \"coral\",\n",
    "    \"model.timm_image.checkpoint_name\": \"resnet50\",\n",
    "    \"model.hf_text.checkpoint_name\": \"prajjwal1/bert-tiny\",\n",
    "}\n",
    "\n",
    "# --- 4. CORAL + EfficientNet-B0 (efficient architecture) ---\n",
    "experiments[\"coral_efficientnet_b0\"] = {\n",
    "    **base_config,\n",
    "    \"optim.loss_func\": \"coral\",\n",
    "    \"model.timm_image.checkpoint_name\": \"efficientnet_b0\",\n",
    "    \"model.hf_text.checkpoint_name\": \"prajjwal1/bert-tiny\",\n",
    "}\n",
    "\n",
    "# --- 5. CORAL + ConvNeXt-Tiny (modern ConvNet) ---\n",
    "experiments[\"coral_convnext_tiny\"] = {\n",
    "    **base_config,\n",
    "    \"optim.loss_func\": \"coral\",\n",
    "    \"model.timm_image.checkpoint_name\": \"convnext_tiny\",\n",
    "    \"model.hf_text.checkpoint_name\": \"prajjwal1/bert-tiny\",\n",
    "}\n",
    "\n",
    "# --- 6. CORAL + Swin-Base (Vision Transformer) ---\n",
    "experiments[\"coral_swin_base\"] = {\n",
    "    **base_config,\n",
    "    \"optim.loss_func\": \"coral\",\n",
    "    \"model.timm_image.checkpoint_name\": \"swin_base_patch4_window7_224\",\n",
    "    \"model.hf_text.checkpoint_name\": \"prajjwal1/bert-tiny\",\n",
    "}\n",
    "\n",
    "# --- 7. CORAL + ResNet18 + Electra-Small (better text encoder for tabular) ---\n",
    "experiments[\"coral_resnet18_electra_small\"] = {\n",
    "    **base_config,\n",
    "    \"optim.loss_func\": \"coral\",\n",
    "    \"model.timm_image.checkpoint_name\": \"resnet18\",\n",
    "    \"model.hf_text.checkpoint_name\": \"google/electra-small-discriminator\",\n",
    "}\n",
    "\n",
    "# --- 8. CORAL + ResNet18 + DeBERTa-v3-small (strong text encoder) ---\n",
    "experiments[\"coral_resnet18_deberta_small\"] = {\n",
    "    **base_config,\n",
    "    \"optim.loss_func\": \"coral\",\n",
    "    \"model.timm_image.checkpoint_name\": \"resnet18\",\n",
    "    \"model.hf_text.checkpoint_name\": \"microsoft/deberta-v3-small\",\n",
    "}\n",
    "\n",
    "# --- 9. CORAL + ResNet50 + Transformer Fusion ---\n",
    "experiments[\"coral_resnet50_transformer_fusion\"] = {\n",
    "    **base_config,\n",
    "    \"optim.loss_func\": \"coral\",\n",
    "    \"model.timm_image.checkpoint_name\": \"resnet50\",\n",
    "    \"model.hf_text.checkpoint_name\": \"prajjwal1/bert-tiny\",\n",
    "    \"model.names\": [\"timm_image\", \"hf_text\", \"fusion_transformer\"],\n",
    "    \"model.fusion_transformer.hidden_size\": 128,\n",
    "    \"model.fusion_transformer.num_blocks\": 2,\n",
    "}\n",
    "\n",
    "# --- 10. CORAL + ResNet18 + FT-Transformer (tabular-specific) ---\n",
    "# Uses FT-Transformer for tabular features instead of text encoder\n",
    "experiments[\"coral_resnet18_ft_transformer\"] = {\n",
    "    **base_config,\n",
    "    \"optim.loss_func\": \"coral\",\n",
    "    \"model.timm_image.checkpoint_name\": \"resnet18\",\n",
    "    \"model.names\": [\"timm_image\", \"ft_transformer\", \"fusion_mlp\"],\n",
    "    \"model.ft_transformer.num_blocks\": 2,\n",
    "}\n",
    "\n",
    "# --- 11. CORAL + MobileNetV3 (lightweight, fast) ---\n",
    "experiments[\"coral_mobilenetv3\"] = {\n",
    "    **base_config,\n",
    "    \"optim.loss_func\": \"coral\",\n",
    "    \"model.timm_image.checkpoint_name\": \"mobilenetv3_large_100\",\n",
    "    \"model.hf_text.checkpoint_name\": \"prajjwal1/bert-tiny\",\n",
    "}\n",
    "\n",
    "# --- 12. CORAL + ViT-Base CLIP (CLIP-pretrained vision) ---\n",
    "experiments[\"coral_vit_clip\"] = {\n",
    "    **base_config,\n",
    "    \"optim.loss_func\": \"coral\",\n",
    "    \"model.timm_image.checkpoint_name\": \"vit_base_patch16_clip_224.laion2b_ft_in12k_in1k\",\n",
    "    \"model.hf_text.checkpoint_name\": \"prajjwal1/bert-tiny\",\n",
    "}\n",
    "\n",
    "print(f\"Defined {len(experiments)} experiments:\")\n",
    "for name in experiments:\n",
    "    cfg = experiments[name]\n",
    "    loss = cfg.get(\"optim.loss_func\", \"cross_entropy\")\n",
    "    img = cfg.get(\"model.timm_image.checkpoint_name\", \"default\")\n",
    "    txt = cfg.get(\"model.hf_text.checkpoint_name\", \"N/A\")\n",
    "    names = cfg.get(\"model.names\", \"default (timm_image + hf_text + fusion_mlp)\")\n",
    "    print(f\"  {name:40s} | loss={loss:15s} | img={img}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80cfd22",
   "metadata": {},
   "source": [
    "## Run Experiments\n",
    "\n",
    "Select which experiments to run below. Results are collected in a DataFrame for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e02f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SELECT EXPERIMENTS TO RUN\n",
    "# ============================================================\n",
    "# Comment/uncomment to choose which experiments to run.\n",
    "# Start with a few fast ones, then add more.\n",
    "\n",
    "experiments_to_run = [\n",
    "    \"coral_resnet18\",                 # Fast baseline with CORAL\n",
    "    \"ce_resnet18\",                    # CrossEntropy baseline (compare loss functions)\n",
    "    \"coral_resnet50\",                 # Stronger CNN\n",
    "    \"coral_efficientnet_b0\",          # Efficient architecture\n",
    "    # \"coral_convnext_tiny\",          # Modern ConvNet (slower)\n",
    "    # \"coral_swin_base\",             # Vision Transformer (slower, needs GPU)\n",
    "    # \"coral_resnet18_electra_small\", # Better text encoder\n",
    "    # \"coral_resnet18_deberta_small\", # Strong text encoder (slower)\n",
    "    # \"coral_resnet50_transformer_fusion\",  # Transformer fusion\n",
    "    # \"coral_resnet18_ft_transformer\",      # FT-Transformer for tabular\n",
    "    # \"coral_mobilenetv3\",            # Lightweight\n",
    "    # \"coral_vit_clip\",               # CLIP-pretrained ViT (needs GPU)\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# RUN LOOP\n",
    "# ============================================================\n",
    "results = []\n",
    "predictors = {}\n",
    "\n",
    "for exp_name in experiments_to_run:\n",
    "    print(f\"\\n{'#'*70}\")\n",
    "    print(f\"# EXPERIMENT: {exp_name}\")\n",
    "    print(f\"{'#'*70}\\n\")\n",
    "\n",
    "    config = experiments[exp_name]\n",
    "    save_path = f\"./experiment_models/{exp_name}\"\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "\n",
    "        predictor = MultiModalPredictor(\n",
    "            label=LABEL_COL,\n",
    "            problem_type=\"multiclass\",\n",
    "            eval_metric=\"accuracy\",\n",
    "            path=save_path,\n",
    "        )\n",
    "\n",
    "        predictor.fit(\n",
    "            train_data=train_df,\n",
    "            hyperparameters=config,\n",
    "            time_limit=TIME_LIMIT,\n",
    "        )\n",
    "\n",
    "        # Predict\n",
    "        preds = predictor.predict(test_df.drop(columns=[LABEL_COL]))\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        # Compute metrics\n",
    "        metrics = compute_ordinal_metrics(test_df[LABEL_COL].values, preds.values)\n",
    "        metrics[\"experiment\"] = exp_name\n",
    "        metrics[\"loss\"] = config.get(\"optim.loss_func\", \"cross_entropy\")\n",
    "        metrics[\"image_backbone\"] = config.get(\"model.timm_image.checkpoint_name\", \"N/A\")\n",
    "        metrics[\"text_encoder\"] = config.get(\"model.hf_text.checkpoint_name\", \"N/A\")\n",
    "        metrics[\"fusion\"] = \"transformer\" if \"fusion_transformer\" in str(config.get(\"model.names\", \"\")) else \"mlp\"\n",
    "        metrics[\"time_sec\"] = round(elapsed, 1)\n",
    "\n",
    "        results.append(metrics)\n",
    "        predictors[exp_name] = predictor\n",
    "\n",
    "        print_metrics(metrics, name=exp_name)\n",
    "        print(f\"  Time: {elapsed:.1f}s\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå FAILED: {exp_name}\")\n",
    "        print(f\"   Error: {e}\")\n",
    "        results.append({\n",
    "            \"experiment\": exp_name,\n",
    "            \"accuracy\": None,\n",
    "            \"within_one_accuracy\": None,\n",
    "            \"mae\": None,\n",
    "            \"quadratic_kappa\": None,\n",
    "            \"loss\": config.get(\"optim.loss_func\", \"cross_entropy\"),\n",
    "            \"image_backbone\": config.get(\"model.timm_image.checkpoint_name\", \"N/A\"),\n",
    "            \"text_encoder\": config.get(\"model.hf_text.checkpoint_name\", \"N/A\"),\n",
    "            \"fusion\": \"N/A\",\n",
    "            \"time_sec\": None,\n",
    "            \"error\": str(e),\n",
    "        })\n",
    "\n",
    "print(f\"\\n\\n{'='*70}\")\n",
    "print(f\"ALL EXPERIMENTS COMPLETED ({len(results)}/{len(experiments_to_run)})\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b85893a",
   "metadata": {},
   "source": [
    "## Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90149ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RESULTS TABLE\n",
    "# ============================================================\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort by within-one accuracy (most relevant for ordinal)\n",
    "display_cols = [\n",
    "    \"experiment\", \"loss\", \"image_backbone\", \"text_encoder\", \"fusion\",\n",
    "    \"accuracy\", \"within_one_accuracy\", \"mae\", \"quadratic_kappa\", \"time_sec\"\n",
    "]\n",
    "available_cols = [c for c in display_cols if c in results_df.columns]\n",
    "results_df_sorted = results_df[available_cols].sort_values(\"within_one_accuracy\", ascending=False)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"EXPERIMENT RESULTS (sorted by Within-One Accuracy)\")\n",
    "print(\"=\"*100)\n",
    "print(results_df_sorted.to_string(index=False, float_format=\"%.4f\"))\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Highlight best results\n",
    "if results_df[\"within_one_accuracy\"].notna().any():\n",
    "    best_w1 = results_df.loc[results_df[\"within_one_accuracy\"].idxmax()]\n",
    "    best_acc = results_df.loc[results_df[\"accuracy\"].idxmax()]\n",
    "    best_mae = results_df.loc[results_df[\"mae\"].idxmin()]\n",
    "    best_qwk = results_df.loc[results_df[\"quadratic_kappa\"].idxmax()]\n",
    "\n",
    "    print(f\"\\nüèÜ Best Within-One Accuracy: {best_w1['experiment']} ({best_w1['within_one_accuracy']:.4f})\")\n",
    "    print(f\"üèÜ Best Exact Accuracy:     {best_acc['experiment']} ({best_acc['accuracy']:.4f})\")\n",
    "    print(f\"üèÜ Best MAE:                {best_mae['experiment']} ({best_mae['mae']:.4f})\")\n",
    "    print(f\"üèÜ Best Quadratic Kappa:    {best_qwk['experiment']} ({best_qwk['quadratic_kappa']:.4f})\")\n",
    "\n",
    "# CORAL vs CrossEntropy comparison\n",
    "coral_results = results_df[results_df[\"loss\"] == \"coral\"]\n",
    "ce_results = results_df[results_df[\"loss\"] == \"cross_entropy\"]\n",
    "\n",
    "if len(coral_results) > 0 and len(ce_results) > 0:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"CORAL vs CrossEntropy (averaged across experiments)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for metric in [\"accuracy\", \"within_one_accuracy\", \"mae\", \"quadratic_kappa\"]:\n",
    "        coral_avg = coral_results[metric].mean()\n",
    "        ce_avg = ce_results[metric].mean()\n",
    "        better = \"CORAL\" if (coral_avg > ce_avg if metric != \"mae\" else coral_avg < ce_avg) else \"CE\"\n",
    "        print(f\"  {metric:25s}: CORAL={coral_avg:.4f}  CE={ce_avg:.4f}  ‚Üí {better} wins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251780c2",
   "metadata": {},
   "source": [
    "## Detailed Analysis: Confusion Matrix & Error Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf29916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DETAILED ANALYSIS FOR BEST MODEL\n",
    "# ============================================================\n",
    "\n",
    "if results_df[\"within_one_accuracy\"].notna().any():\n",
    "    best_name = results_df.loc[results_df[\"within_one_accuracy\"].idxmax(), \"experiment\"]\n",
    "    best_pred = predictors[best_name]\n",
    "\n",
    "    preds = best_pred.predict(test_df.drop(columns=[LABEL_COL]))\n",
    "    y_true = test_df[LABEL_COL].values\n",
    "    y_pred = preds.values\n",
    "\n",
    "    # Confusion matrix\n",
    "    classes = sorted(test_df[LABEL_COL].unique())\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "    cm_df = pd.DataFrame(cm, index=[f\"True {c}\" for c in classes], columns=[f\"Pred {c}\" for c in classes])\n",
    "\n",
    "    print(f\"Confusion Matrix for: {best_name}\")\n",
    "    print(cm_df)\n",
    "\n",
    "    # Error distribution\n",
    "    errors = y_pred - y_true\n",
    "    print(f\"\\nError Distribution (Predicted - True):\")\n",
    "    error_counts = pd.Series(errors).value_counts().sort_index()\n",
    "    for err, count in error_counts.items():\n",
    "        bar = \"‚ñà\" * int(count / max(error_counts) * 30)\n",
    "        print(f\"  {err:+d}: {count:4d} {bar}\")\n",
    "\n",
    "    # Per-class accuracy\n",
    "    print(f\"\\nPer-Class Metrics:\")\n",
    "    for c in classes:\n",
    "        mask = y_true == c\n",
    "        if mask.sum() > 0:\n",
    "            class_acc = (y_pred[mask] == c).mean()\n",
    "            class_w1 = (np.abs(y_pred[mask] - c) <= 1).mean()\n",
    "            class_mae = np.abs(y_pred[mask] - c).mean()\n",
    "            print(f\"  Class {c}: n={mask.sum():4d}  acc={class_acc:.3f}  within1={class_w1:.3f}  mae={class_mae:.3f}\")\n",
    "\n",
    "    # Probability analysis\n",
    "    try:\n",
    "        probs = best_pred.predict_proba(test_df.drop(columns=[LABEL_COL]))\n",
    "        print(f\"\\nProbability Distribution (first 5 samples):\")\n",
    "        print(probs.head())\n",
    "        print(f\"\\nProbabilities sum to 1? {np.allclose(probs.sum(axis=1), 1.0)}\")\n",
    "        print(f\"Mean max probability (confidence): {probs.max(axis=1).mean():.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nCould not compute probabilities: {e}\")\n",
    "else:\n",
    "    print(\"No successful experiments to analyze.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92dab6f",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d5169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "results_df.to_csv(\"experiment_results.csv\", index=False)\n",
    "print(f\"Results saved to experiment_results.csv\")\n",
    "print(f\"\\nFinal summary:\")\n",
    "print(results_df_sorted[[\"experiment\", \"accuracy\", \"within_one_accuracy\", \"mae\", \"quadratic_kappa\"]].to_string(index=False, float_format=\"%.4f\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
